{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IglGt4_J4lTf",
        "outputId": "c84d20b1-d39f-47a5-8562-2ee3eaf8b481"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir input_csvs output_csvs"
      ],
      "metadata": {
        "id": "AC-a9iRH48ic"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important\n",
        "\n",
        "Add your csv to classify to input_csvs directory"
      ],
      "metadata": {
        "id": "bDkix5RD5B5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_html(html_content):\n",
        "    try:\n",
        "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "        text = soup.get_text(separator=\" \", strip=True)\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "dXjlyqkeQ5GZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9dqc46c4X-O",
        "outputId": "efe89ce7-1219-4288-ba39-1be8ee815ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-eb91fe22a16a>:9: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
            "\n",
            "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
            "\n",
            "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import MarkupResemblesLocatorWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
            "    \n",
            "  soup = BeautifulSoup(html_content, \"html.parser\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: oracle database_posts_with_comments_answers.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    vs = analyzer.polarity_scores(extract_text_from_html(str(text)))\n",
        "\n",
        "    return vs['compound']\n",
        "\n",
        "def process_csv_files(input_dir, output_dir, text_column='text'):\n",
        "    \"\"\"\n",
        "    Processes all CSV files in the input directory, adds a 'sentiment' column,\n",
        "    and saves the modified CSV files to the output directory.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing CSV files.\n",
        "        output_dir (str): Path to the directory to save the modified CSV files.\n",
        "        text_column (str): Name of the column containing the text to analyze.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith('.csv'):\n",
        "            input_filepath = os.path.join(input_dir, filename)\n",
        "            output_filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "            try:\n",
        "                df = pd.read_csv(input_filepath)\n",
        "\n",
        "                if text_column not in df.columns:\n",
        "                    print(f\"Warning: Column '{text_column}' not found in {filename}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                df['sentiment'] = df[text_column].apply(analyze_sentiment)\n",
        "                df.to_csv(output_filepath, index=False)\n",
        "                print(f\"Processed and saved: {filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_directory = \"input_csvs\"\n",
        "    output_directory = \"output_csvs\"\n",
        "    text_column_name = \"content\"\n",
        "\n",
        "    process_csv_files(input_directory, output_directory, text_column_name)"
      ]
    }
  ]
}